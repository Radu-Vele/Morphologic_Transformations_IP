{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "475d46e3",
   "metadata": {},
   "source": [
    "# Morphologic Transformations Visualizations ğŸ”²\n",
    "\n",
    "This notebook contains algorithms for visualizing some basic morphologic transformations such as erosion, dilation, and region filling.\n",
    "\n",
    "It serves the purpose of offering a better understanding in the process of exploring Image Processing. ğŸ“š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "560390c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import imageio # for creating gifs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "498c2153",
   "metadata": {},
   "source": [
    "# Dilation and Erosion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffd0cbd9",
   "metadata": {},
   "source": [
    "## Out-of-box behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "270fe370",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = cv.imread(\"./img/mon1thr1_bw.bmp\", cv.IMREAD_GRAYSCALE)\n",
    "cv.imshow(\"source\", input_img)\n",
    "\n",
    "default_dilated = cv.dilate(input_img, None, iterations = 1)\n",
    "\n",
    "default_eroded = cv.erode(input_img, None, iterations = 1)\n",
    "\n",
    "cv.imshow(\"default dilation\", default_dilated)\n",
    "cv.imshow(\"default eroded\", default_eroded)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyWindow(\"source\")\n",
    "cv.destroyWindow(\"default dilation\")\n",
    "cv.destroyWindow(\"default eroded\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b2d5cda",
   "metadata": {},
   "source": [
    "*Remark:* The behavior is the opposite way w.r.t the expectation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16a3b38f",
   "metadata": {},
   "source": [
    "## Custom Implementation and Visualization\n",
    "\n",
    "Requirements:\n",
    "- the input image is a very small one containing one or more objects (black pixels) over a white background\n",
    "    - using a large image may lead to memory allocation errors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81192939",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "The dilation and erosion routines need some additional functions for creating images with the intermmediary steps. These functions are featured below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62618880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOffsets(structuring_elem):\n",
    "    \"\"\"\n",
    "    Extract the coordinates of the structuring element cells that contain a 1.\n",
    "    Return them as a list of tuples\n",
    "    \"\"\"\n",
    "    elem_matrix, origin = structuring_elem\n",
    "    x_origin, y_origin = origin\n",
    "\n",
    "    (x_coord, y_coord) = np.where(elem_matrix == 1)    \n",
    "    x_coord = x_coord - x_origin    \n",
    "    y_coord = y_coord - y_origin\n",
    "    \n",
    "    offsets = list(zip(x_coord, y_coord))\n",
    "    return offsets\n",
    "    \n",
    "def inImage(curr_i, curr_j, rows, cols):\n",
    "    \"\"\"\n",
    "    Check if a pixel at the given coordinates is in the image\n",
    "    \"\"\"\n",
    "    if curr_i > 0 and curr_i < rows:\n",
    "        if curr_j > 0 and curr_j < cols:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def zoom_in(src, dims):\n",
    "    \"\"\"\n",
    "    Return a zoomed in version of the image. The percentage inverse proportional to the area.\n",
    "    Use nearest neighbor interpolation to preserve sharpness.\n",
    "    \"\"\"\n",
    "    if dims == 3:\n",
    "        height, width, _ = src.shape\n",
    "    else:\n",
    "        height, width = src.shape\n",
    "    area = height * width\n",
    "    percentage = 1290 * 3000 / area # experimentally adjusted values\n",
    "    new_height = int(height * percentage / 100) \n",
    "    new_width = int(width * percentage / 100)\n",
    "    dst = cv.resize(src, (new_width, new_height), interpolation = cv.INTER_NEAREST)\n",
    "    return dst\n",
    "\n",
    "def overlapStructElem(src, acc, src_after, i, j, structuring_elem):\n",
    "    \"\"\"\n",
    "    Create an image that overlaps the structuring element and the image that is being transformed.\n",
    "    Also adds snapshots of the source image before and after the dilation/erosion overlapped\n",
    "    with the structuring element.\n",
    "    \"\"\"\n",
    "    offsets = getOffsets(structuring_elem)\n",
    "    rows, cols = acc.shape\n",
    "    to_return= np.full((rows, cols, 3), 255, np.uint8) \n",
    "\n",
    "    # color object pixels black\n",
    "    to_return[:, :, 0] = acc\n",
    "    to_return[:, :, 1] = acc\n",
    "    to_return[:, :, 2] = acc\n",
    "\n",
    "    for offset_i, offset_j in offsets: # navigate through the structuring element pixels of value 1\n",
    "        index_i = i + offset_i\n",
    "        index_j = j + offset_j\n",
    "        if (to_return[index_i, index_j, 1] == 0): # intersection between struct elem and object (dark green)\n",
    "            to_return[index_i, index_j, 1] = 99\n",
    "            to_return[index_i, index_j, 2] = 18\n",
    "        else: # structuring element outside object (green)\n",
    "            to_return[index_i, index_j, 0] = 0\n",
    "            to_return[index_i, index_j, 2] = 0\n",
    "\n",
    "    # highlight object center (yellow)\n",
    "    to_return[i, j, 1] = 255\n",
    "    to_return[i, j, 2] = 255\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Add the snapshots containing source ++ structuring element before and after dilation\n",
    "    \"\"\"\n",
    "    \n",
    "    elem_matrix, origin = structuring_elem\n",
    "    x_origin, y_origin = origin\n",
    "    struct_rows, struct_cols = elem_matrix.shape\n",
    "    \n",
    "    padding = 2\n",
    "    window_start_i = i - x_origin - padding\n",
    "    window_end_i = i + (struct_rows - x_origin) + padding\n",
    "    window_start_j = j - y_origin - padding\n",
    "    window_end_j = j + (struct_cols - y_origin) + padding\n",
    "\n",
    "    # BEFORE \n",
    "    before = np.full((struct_rows + 2 * padding, struct_cols + 2 * padding, 3), 255, np.uint8)\n",
    "    src_crop = src[window_start_i : window_end_i, window_start_j : window_end_j] # extract region of interest from src\n",
    "\n",
    "    # Add source object pixels\n",
    "    before[:, :, 0] = src_crop\n",
    "    before[:, :, 1] = src_crop\n",
    "    before[:, :, 2] = src_crop\n",
    "\n",
    "    # Add structuring element\n",
    "    for offset_i, offset_j in offsets:\n",
    "        index_i = x_origin + offset_i + padding\n",
    "        index_j = y_origin + offset_j + padding\n",
    "        if(before[index_i, index_j, 1] == 0): # intersection between struct elem and object (dark green)\n",
    "            before[index_i, index_j, 1] = 99\n",
    "            before[index_i, index_j, 2] = 18\n",
    "        else: # structuring element outside object (green)\n",
    "            before[index_i, index_j, 0] = 0\n",
    "            before[index_i, index_j, 2] = 0\n",
    "\n",
    "    # Highlight center if it has the value 1 in the structuring element (yellow)\n",
    "    if((x_origin, y_origin) in offsets):\n",
    "        before[x_origin + padding, y_origin + padding, 1] = 255\n",
    "        before[x_origin + padding, y_origin + padding, 2] = 255\n",
    "\n",
    "    # Overlap the output and the BEFORE snapshot in the top left corner\n",
    "    to_return[0 : struct_rows + 2 * padding, 0: struct_cols + 2 * padding, : ] = before\n",
    "    \n",
    "    # AFTER\n",
    "    after = np.full((struct_rows + 2 * padding, struct_cols + 2 * padding, 3), 255, np.uint8)\n",
    "    src_after_crop = src_after[window_start_i : window_end_i, window_start_j : window_end_j]\n",
    "\n",
    "    after[:, :, 0] = src_after_crop  \n",
    "    after[:, :, 1] = src_after_crop    \n",
    "    after[:, :, 2] = src_after_crop\n",
    "\n",
    "    # Add structuring element (with offset of 2)\n",
    "    for offset_i, offset_j in offsets:\n",
    "        index_i = x_origin + offset_i + 2\n",
    "        index_j = y_origin + offset_j + 2\n",
    "        if(after[index_i, index_j, 1] == 0): # intersection between struct elem and object (dark green)\n",
    "            after[index_i, index_j, 1] = 99\n",
    "            after[index_i, index_j, 2] = 18\n",
    "        else: # structuring element outside object (green)\n",
    "            after[index_i, index_j, 0] = 0\n",
    "            after[index_i, index_j, 2] = 0\n",
    "\n",
    "    # Overlap the output and the AFTER snapshot after the before snapshot\n",
    "    to_return[0 : struct_rows + 2 * padding , struct_cols + 2 * padding + 1 : (struct_cols + 2 * padding + 1 + struct_cols + 2 * padding), :] = after\n",
    "\n",
    "    # swap the third and first cols (imageio works with RGB not GRB)\n",
    "    to_return[:, :, [0, 2]] = to_return[:, :, [2, 0]]\n",
    "    return to_return\n",
    "\n",
    "def gifFromImages(src_frames, out_path, duration):\n",
    "    \"\"\"\n",
    "    Create a gif from the list of frames src_frames\n",
    "    \"\"\"\n",
    "    imageio.mimsave(os.path.join(out_path), src_frames, duration=duration)\n",
    "    return\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43a9b282",
   "metadata": {},
   "source": [
    "### Implementation of dilation and erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23dd5f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customDilationWithVisualization(src, structuring_elem, iterations):\n",
    "    \"\"\"\n",
    "    Performs a dilation on the source image. It builds a list of images representing\n",
    "    intermmediate steps through the algorithm\n",
    "    \"\"\"\n",
    "    rows, cols = src.shape\n",
    "    structuring_elem_offsets = getOffsets(structuring_elem)\n",
    "    ret_images = []\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        acc = np.copy(src) # accumulator\n",
    "        \n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                if src[i, j] == 0:\n",
    "                    last_i, last_j = i,j # save the last intersection between struc. elem. and object                    \n",
    "                    \n",
    "                    acc_cpy = np.copy(acc) # accumulator before the dilation\n",
    "                    src_post = np.copy(src) # source after the dilation\n",
    "\n",
    "                    # mark the center as background\n",
    "                    acc[i, j] = 255 \n",
    "                    src_post[i, j] = 255\n",
    "                    \n",
    "                    for (offset_i, offset_j) in structuring_elem_offsets:\n",
    "                        if inImage(i + offset_i, j + offset_j, rows, cols):\n",
    "                            acc[i + offset_i, j + offset_j] = 0\n",
    "                            src_post[i + offset_i, j + offset_j] = 0\n",
    "                    overlapped = overlapStructElem(src, acc_cpy, src_post, i, j, structuring_elem)\n",
    "                    ret_images.append(zoom_in(overlapped, 3)) # add to the list of frames    \n",
    "\n",
    "        overlapped = overlapStructElem(src, acc, src_post, last_i, last_j, structuring_elem)\n",
    "        ret_images.append(zoom_in(overlapped, 3))\n",
    "        src = np.copy(acc)\n",
    "\n",
    "    return ret_images\n",
    "\n",
    "def customErosionWithVisualization(src, structuring_elem, iterations):\n",
    "    \"\"\"\n",
    "    Performs an erosion on the source image. It builds a list of images representing\n",
    "    intermmediate steps through the algorithm\n",
    "    \"\"\"\n",
    "    rows, cols = src.shape\n",
    "    acc = np.copy(src)\n",
    "    structuring_elem_offsets = getOffsets(structuring_elem)\n",
    "    ret_images = []\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                curr_pixel = src[i, j]\n",
    "                if curr_pixel == 0:\n",
    "                    last_i, last_j = i, j\n",
    "\n",
    "                    acc_cpy = np.copy(acc)\n",
    "                    src_after = np.copy(src)\n",
    "\n",
    "                    all_neigbors_are_object = True\n",
    "                    for (offset_i, offset_j) in structuring_elem_offsets:\n",
    "                        if inImage(i + offset_i, j + offset_j, rows, cols):\n",
    "                            if src[i + offset_i, j + offset_j] == 255:\n",
    "                                all_neigbors_are_object = False\n",
    "                                break\n",
    "\n",
    "                    if all_neigbors_are_object:\n",
    "                        acc[i, j] = 0 # color the origin as object\n",
    "                        src_after[i, j] = 0\n",
    "                    else:\n",
    "                        acc[i, j] = 255\n",
    "                        src_after[i, j] = 255\n",
    "                    \n",
    "                    ovelapped = overlapStructElem(src, acc_cpy, src_after, i, j, structuring_elem)\n",
    "                    ret_images.append(zoom_in(ovelapped, 3))\n",
    "        \n",
    "        ovelapped = overlapStructElem(src, acc, src_after, last_i, last_j, structuring_elem)\n",
    "        ret_images.append(zoom_in(ovelapped, 3))\n",
    "\n",
    "        src = np.copy(acc)\n",
    "\n",
    "    return ret_images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "767f200d",
   "metadata": {},
   "source": [
    "### Generating the desired gifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2adc39a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(isDilation, input_path, structuring_element, iterations, output_path, frame_duration) :\n",
    "    input_img = cv.imread(input_path, cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if isDilation:    \n",
    "        frames = customDilationWithVisualization(input_img, structuring_element, iterations)\n",
    "    else:   \n",
    "        frames = customErosionWithVisualization(input_img, structuring_element, iterations)\n",
    "    \n",
    "    gifFromImages(frames, output_path, frame_duration)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9846ad0b",
   "metadata": {},
   "source": [
    "#### Dilation Gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7959d3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    struct_element = (np.array([[1,0,1]]), (0, 1))\n",
    "    main(True, \"./img/vertical_line.bmp\", struct_element, 2, \"./outDilation/dilation_vertical_gif.gif\", 300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e7b73cd",
   "metadata": {},
   "source": [
    "#### Erosion Gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f407c02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    struct_element = (np.array([[1,1,1],[1,1,1],[1,1,1]]), (1, 1))\n",
    "    main(False, \"./img/infinity.bmp\", struct_element, 1, \"./outErosion/erosion_gif.gif\", 300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f93ffb6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cc31175",
   "metadata": {},
   "source": [
    "# Region Filling Visualization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c09063f",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2dcf4ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complementImg(src):\n",
    "    rows, cols = src.shape\n",
    "    dst = np.copy(src)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if src[i, j] == 255:\n",
    "                dst[i, j] = 0\n",
    "            else:\n",
    "                dst[i, j] = 255\n",
    "\n",
    "    return dst\n",
    "\n",
    "def dilation(src, structuring_element):\n",
    "    \"\"\"\n",
    "    Performs a dilation on the source image. It builds a list of images representing\n",
    "    intermmediate steps through the algorithm\n",
    "    \"\"\"\n",
    "    rows, cols = src.shape\n",
    "    structuring_elem_offsets = getOffsets(structuring_element)\n",
    "\n",
    "    acc = np.copy(src) # accumulator\n",
    "        \n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if src[i, j] == 0:      \n",
    "                # mark the center as background\n",
    "                acc[i, j] = 255 \n",
    "                for (offset_i, offset_j) in structuring_elem_offsets:\n",
    "                    if inImage(i + offset_i, j + offset_j, rows, cols):\n",
    "                        acc[i + offset_i, j + offset_j] = 0\n",
    "    return acc\n",
    "\n",
    "def intersect(mat1, mat2):\n",
    "    \"\"\"\n",
    "    Assumes the images have the same size\n",
    "    \"\"\"\n",
    "    rows, cols = mat1.shape\n",
    "    dst = np.full((rows, cols), 255, np.uint8)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if (mat1[i, j] == mat2[i, j] and mat1[i, j] == 0):\n",
    "                dst[i, j] = 0\n",
    "\n",
    "    return dst\n",
    "\n",
    "def union(mat1, mat2):\n",
    "    rows, cols = mat1.shape\n",
    "    dst = np.full((rows, cols), 255, np.uint8)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if (mat1[i, j] == 0 or mat2[i, j] == 0):\n",
    "                dst[i, j] = 0\n",
    "    return dst\n",
    "\n",
    "def computeArea(src): \n",
    "    rows, cols = src.shape\n",
    "    area = 0\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if src[i, j] == 0:\n",
    "                area += 1 \n",
    "    return area\n",
    "\n",
    "def centerOfMass(src):\n",
    "    rows, cols = src.shape\n",
    "    row_sum = 0\n",
    "    col_sum = 0\n",
    "    area = computeArea(src)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if src[i, j] == 0:\n",
    "                row_sum += i\n",
    "                col_sum += j\n",
    "\n",
    "    center_i = int (row_sum / area)\n",
    "    center_j = int (col_sum / area)\n",
    "\n",
    "    return (center_i, center_j)\n",
    "\n",
    "def snapshotGenerator(left, dilated, right, option):\n",
    "    \"\"\"\n",
    "    Generate snapshot from the region filling algorithm\n",
    "    Option: 0 - just place images side by side\n",
    "            1 - in the left part show intersection while in the right part show the remaining part\n",
    "    \"\"\"\n",
    "    rows, cols = left.shape\n",
    "    to_return = np.full((rows, 2 * cols, 3), 255, np.uint8)\n",
    "    if option == 0:\n",
    "        to_return[:, 0:cols, 0] = left\n",
    "        to_return[:, 0:cols, 1] = left\n",
    "        to_return[:, 0:cols, 2] = left\n",
    "\n",
    "        to_return[:, cols:(2 * cols), 0] = right\n",
    "        to_return[:, cols:(2 * cols), 1] = right\n",
    "        to_return[:, cols:(2 * cols), 2] = right\n",
    "        \n",
    "    elif option == 1:\n",
    "        # left part\n",
    "        to_return[:, 0:cols, 0] = left\n",
    "        to_return[:, 0:cols, 1] = left\n",
    "        to_return[:, 0:cols, 2] = left\n",
    "\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                if left[i, j] == dilated[i, j] and dilated[i, j] == 0: # draw intersection dark green\n",
    "                    to_return[i, j, 1] = 99\n",
    "                    to_return[i, j, 2] = 18\n",
    "                else: # draw the rest of pixels in red\n",
    "                    if dilated[i, j] == 0:   \n",
    "                        to_return[i, j, 0] = 255 # red for imageio\n",
    "                        to_return[i, j, 1] = 0\n",
    "                        to_return[i, j, 2] = 0\n",
    "\n",
    "        # right part\n",
    "        to_return[:, cols:(2 * cols), 0] = right\n",
    "        to_return[:, cols:(2 * cols), 1] = right\n",
    "        to_return[:, cols:(2 * cols), 2] = right\n",
    "    \n",
    "    return to_return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b69b5eef",
   "metadata": {},
   "source": [
    "### Region Filling Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb4bd923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regionFillingWithVisualization(src, struct_element):\n",
    "    rows, cols = src.shape\n",
    "    dst = np.full((rows, cols), 255, np.uint8)\n",
    "\n",
    "    # Color the center of mass black\n",
    "    (x_start, y_start) = centerOfMass(src)\n",
    "    dst[x_start, y_start] = 0\n",
    "\n",
    "    complement = complementImg(src)\n",
    "    snapshots = [] # store the output frames\n",
    "    \n",
    "    sn0 = snapshotGenerator(src, dst, complement, 0) # initial state (original | complemented)\n",
    "    snapshots.append(zoom_in(sn0, 3))\n",
    "    snapshots.append(zoom_in(sn0, 3))\n",
    "    snapshots.append(zoom_in(sn0, 3))\n",
    "\n",
    "    while (True):\n",
    "        prv = np.copy(dst)\n",
    "        sn1 = snapshotGenerator(complement, dst, dst, 0) # (complement | current dst)\n",
    "        snapshots.append(zoom_in(sn1, 3))\n",
    "        \n",
    "        dst = dilation(dst, struct_element)\n",
    "        dilated_cpy = np.copy(dst)\n",
    "        sn2 = snapshotGenerator(complement, dst, dst, 0) # (complement | dst dilated)\n",
    "        snapshots.append(zoom_in(sn2, 3))\n",
    "        \n",
    "        dst = intersect(dst, complement)\n",
    "        sn3 = snapshotGenerator(complement, dilated_cpy, dst, 1) # (complement overlapped with dst dilated | intersection of the two)\n",
    "        snapshots.append(zoom_in(sn3, 3))\n",
    "        \n",
    "        if np.array_equal(dst, prv):\n",
    "            break\n",
    "\n",
    "    final_result = union(dst, src)\n",
    "    sn4 = snapshotGenerator(complement, final_result, final_result, 0) # (complement | final result)\n",
    "    snapshots.append(zoom_in(sn4, 3))\n",
    "\n",
    "    sn5 = snapshotGenerator(src, final_result, final_result, 0) # (source | final result)\n",
    "    snapshots.append(zoom_in(sn5, 3))\n",
    "\n",
    "    return snapshots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccbbd961",
   "metadata": {},
   "source": [
    "### Generate Visualization Gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90031468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    input_img = cv.imread(\"./img/l.bmp\", cv.IMREAD_GRAYSCALE)\n",
    "    struct_elem = (np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]]), (1, 1))\n",
    "    frames = regionFillingWithVisualization(input_img, struct_elem)\n",
    "\n",
    "    # Generate region filling gif\n",
    "    gifFromImages(frames, \"./outRegionFilling/rf_gif.gif\", 600)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
