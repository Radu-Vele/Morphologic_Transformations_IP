{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "475d46e3",
   "metadata": {},
   "source": [
    "# Morphologic Transformations Visualizations ğŸ”²\n",
    "\n",
    "This notebook contains algorithms for visualizing some basic morphologic transformations such as erosion, dilation, and region filling.\n",
    "\n",
    "It serves the purpose of offering a better understanding in the process of exploring Image Processing. ğŸ“š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "560390c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import imageio # for creating gifs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "498c2153",
   "metadata": {},
   "source": [
    "# Dilation and Erosion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffd0cbd9",
   "metadata": {},
   "source": [
    "## Out-of-box behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "270fe370",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = cv.imread(\"./img/infinity.bmp\", cv.IMREAD_GRAYSCALE)\n",
    "cv.imshow(\"source\", input_img)\n",
    "\n",
    "default_dilated = cv.dilate(input_img, None, iterations = 1)\n",
    "\n",
    "default_eroded = cv.erode(input_img, None, iterations = 1)\n",
    "\n",
    "cv.imshow(\"default dilation\", default_dilated)\n",
    "cv.imshow(\"default eroded\", default_eroded)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyWindow(\"source\")\n",
    "cv.destroyWindow(\"default dilation\")\n",
    "cv.destroyWindow(\"default eroded\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b2d5cda",
   "metadata": {},
   "source": [
    "*Remark:* The behavior is the opposite way w.r.t the expectation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16a3b38f",
   "metadata": {},
   "source": [
    "## Custom Implementation and Visualization\n",
    "\n",
    "Requirements:\n",
    "- the input image is a very small one containing one or more objects (black pixels) over a white background\n",
    "    - using a large image may lead to memory allocation errors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81192939",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "The dilation and erosion routines need some additional functions for creating images with the intermmediary steps. These functions are featured below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "62618880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOffsets(structuring_elem):\n",
    "    \"\"\"\n",
    "    Extract the coordinates of the structuring element cells that contain a 1.\n",
    "    Return them as a list of tuples\n",
    "    \"\"\"\n",
    "    elem_matrix, origin = structuring_elem\n",
    "    x_origin, y_origin = origin\n",
    "\n",
    "    (x_coord, y_coord) = np.where(elem_matrix == 1)    \n",
    "    x_coord = x_coord - x_origin    \n",
    "    y_coord = y_coord - y_origin\n",
    "    \n",
    "    offsets = list(zip(x_coord, y_coord))\n",
    "    return offsets\n",
    "    \n",
    "def inImage(curr_i, curr_j, rows, cols):\n",
    "    \"\"\"\n",
    "    Check if a pixel at the given coordinates is in the image\n",
    "    \"\"\"\n",
    "    if curr_i > 0 and curr_i < rows:\n",
    "        if curr_j > 0 and curr_j < cols:\n",
    "            \n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def zoom_in(src, dims):\n",
    "    \"\"\"\n",
    "    Return a zoomed in version of the image. The percentage inverse proportional to the area.\n",
    "    Use nearest neighbor interpolation to preserve sharpness.\n",
    "    \"\"\"\n",
    "    if dims == 3:\n",
    "        height, width, _ = src.shape\n",
    "    else:\n",
    "        height, width = src.shape\n",
    "    area = height * width\n",
    "    percentage = 1290 * 3000 / area # experimentally adjusted values\n",
    "    new_height = int(height * percentage / 100) \n",
    "    new_width = int(width * percentage / 100)\n",
    "    dst = cv.resize(src, (new_width, new_height), interpolation = cv.INTER_NEAREST)\n",
    "    return dst\n",
    "\n",
    "def overlapStructElem(src, acc, src_after, i, j, structuring_elem, colorCenterInRed, colorCenterInBlue):\n",
    "    \"\"\"\n",
    "    Create an image that overlaps the structuring element and the image that is being transformed.\n",
    "    Also adds snapshots of the source image before and after the dilation/erosion overlapped\n",
    "    with the structuring element.\n",
    "    \"\"\"\n",
    "    offsets = getOffsets(structuring_elem)\n",
    "    rows, cols = acc.shape\n",
    "    to_return= np.full((rows, cols, 3), 255, np.uint8) \n",
    "\n",
    "    # color object pixels black\n",
    "    to_return[:, :, 0] = acc\n",
    "    to_return[:, :, 1] = acc\n",
    "    to_return[:, :, 2] = acc\n",
    "\n",
    "    for offset_i, offset_j in offsets: # navigate through the structuring element pixels of value 1\n",
    "        index_i = i + offset_i\n",
    "        index_j = j + offset_j\n",
    "        if (to_return[index_i, index_j, 1] == 0): # intersection between struct elem and object (dark green)\n",
    "            to_return[index_i, index_j, 1] = 99\n",
    "            to_return[index_i, index_j, 2] = 18\n",
    "        else: # structuring element outside object (green)\n",
    "            to_return[index_i, index_j, 0] = 0\n",
    "            to_return[index_i, index_j, 2] = 0\n",
    "\n",
    "    # highlight object center (yellow)\n",
    "    to_return[i, j, 1] = 255\n",
    "    to_return[i, j, 2] = 255\n",
    "    \n",
    "    \"\"\"\n",
    "    Add the snapshots containing source ++ structuring element before and after dilation\n",
    "    \"\"\"\n",
    "    \n",
    "    elem_matrix, origin = structuring_elem\n",
    "    x_origin, y_origin = origin\n",
    "    struct_rows, struct_cols = elem_matrix.shape\n",
    "    \n",
    "    padding = 2\n",
    "    window_start_i = i - x_origin - padding\n",
    "    window_end_i = i + (struct_rows - x_origin) + padding\n",
    "    window_start_j = j - y_origin - padding\n",
    "    window_end_j = j + (struct_cols - y_origin) + padding\n",
    "\n",
    "    # BEFORE \n",
    "    before = np.full((struct_rows + 2 * padding, struct_cols + 2 * padding, 3), 255, np.uint8)\n",
    "    src_crop = src[window_start_i : window_end_i, window_start_j : window_end_j] # extract region of interest from src\n",
    "\n",
    "    # Add source object pixels\n",
    "    before[:, :, 0] = src_crop\n",
    "    before[:, :, 1] = src_crop\n",
    "    before[:, :, 2] = src_crop\n",
    "\n",
    "    # Add structuring element\n",
    "    for offset_i, offset_j in offsets:\n",
    "        index_i = x_origin + offset_i + padding\n",
    "        index_j = y_origin + offset_j + padding\n",
    "        if(before[index_i, index_j, 1] == 0): # intersection between struct elem and object (dark green)\n",
    "            before[index_i, index_j, 1] = 99\n",
    "            before[index_i, index_j, 2] = 18\n",
    "        else: # structuring element outside object (green)\n",
    "            before[index_i, index_j, 0] = 0\n",
    "            before[index_i, index_j, 2] = 0\n",
    "\n",
    "    # Highlight center if it has the value 1 in the structuring element (yellow)\n",
    "    if((x_origin, y_origin) in offsets):\n",
    "        if colorCenterInRed:\n",
    "            before[x_origin + padding, y_origin + padding, 0] = 0\n",
    "            before[x_origin + padding, y_origin + padding, 1] = 0\n",
    "            before[x_origin + padding, y_origin + padding, 2] = 255\n",
    "        elif colorCenterInBlue: # color in blue\n",
    "            before[x_origin + padding, y_origin + padding, 0] = 255\n",
    "            before[x_origin + padding, y_origin + padding, 1] = 0\n",
    "            before[x_origin + padding, y_origin + padding, 2] = 0\n",
    "        else:\n",
    "            before[x_origin + padding, y_origin + padding, 0] = 0\n",
    "            before[x_origin + padding, y_origin + padding, 1] = 255\n",
    "            before[x_origin + padding, y_origin + padding, 2] = 255\n",
    "\n",
    "    # Overlap the output and the BEFORE snapshot in the top left corner\n",
    "    to_return[0 : struct_rows + 2 * padding, 0: struct_cols + 2 * padding, : ] = before\n",
    "    \n",
    "    return to_return\n",
    "\n",
    "def gifFromImages(src_frames, out_path, duration):\n",
    "    \"\"\"\n",
    "    Create a gif from the list of frames src_frames\n",
    "    \"\"\"\n",
    "    imageio.mimsave(os.path.join(out_path), src_frames, duration=duration)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f448f8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom gif speed function\n",
    "# Dependency: Image Magick installed and added to PATH (Windows OS)\n",
    "\n",
    "import subprocess\n",
    "\n",
    "def createGifVariableSpeed(frames, folder_path, initial_duration, increase_speed):\n",
    "    \"\"\"\n",
    "    param: initial duration needs to be passed in centiseconds \n",
    "    \"\"\"\n",
    "    frames_paths = []\n",
    "    frames_len = len(frames)\n",
    "    \n",
    "    # Configurable speed\n",
    "    if increase_speed:\n",
    "        secondary_duration = initial_duration // 2\n",
    "        third_duration = initial_duration // 3\n",
    "        long_duration = initial_duration * 4\n",
    "    else:\n",
    "        secondary_duration = initial_duration\n",
    "        third_duration = initial_duration\n",
    "        long_duration = initial_duration\n",
    "\n",
    "    # save the frames locally\n",
    "    for i, frame in enumerate(frames):\n",
    "        frame_path_name = f\"frame_{i}.bmp\"\n",
    "        full_path = os.path.join(folder_path, frame_path_name)\n",
    "        frames_paths.append(full_path) \n",
    "        cv.imwrite(full_path, frame)\n",
    "\n",
    "    # Build ImageMagick command\n",
    "    command = [\"magick\", \"convert\", \"-verbose\"]\n",
    "\n",
    "    for i, frame_file in enumerate(frames_paths):\n",
    "        if i < frames_len // 4:\n",
    "            command += [\"-delay\", str(initial_duration), frame_file]\n",
    "        elif i < frames_len // 2:\n",
    "            command += [\"-delay\", str(secondary_duration), frame_file]\n",
    "        elif i == frames_len - 1:\n",
    "            command += [\"-delay\", str(long_duration), frame_file] \n",
    "        else:\n",
    "            command += [\"-delay\", str(third_duration), frame_file]\n",
    "\n",
    "    \n",
    "    command += [\"-loop\", \"0\", os.path.join(folder_path, \"output.gif\")]\n",
    "    \n",
    "    subprocess.call(command, shell=True)\n",
    "\n",
    "    full_command = \"\"\n",
    "    for word in command :\n",
    "        full_command += word\n",
    "        full_command += \" \"\n",
    "\n",
    "    print(full_command)\n",
    "\n",
    "    # remove the individual frames\n",
    "    # for frame_file in frames_paths:\n",
    "    #     os.remove(frame_file)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43a9b282",
   "metadata": {},
   "source": [
    "### Implementation of dilation and erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23dd5f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customDilationWithVisualization(src, structuring_elem, iterations):\n",
    "    \"\"\"\n",
    "    Performs a dilation on the source image. It builds a list of images representing\n",
    "    intermmediate steps through the algorithm\n",
    "    \"\"\"\n",
    "    rows, cols = src.shape\n",
    "    structuring_elem_offsets = getOffsets(structuring_elem)\n",
    "    ret_images = []\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        acc = np.copy(src) # accumulator\n",
    "        \n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                if src[i, j] == 0:\n",
    "                    last_i, last_j = i,j # save the last intersection between struc. elem. and object                    \n",
    "                    \n",
    "                    acc_cpy = np.copy(acc) # accumulator before the dilation\n",
    "                    src_post = np.copy(src) # source after the dilation\n",
    "\n",
    "                    # mark the center as background\n",
    "                    acc[i, j] = 255 \n",
    "                    src_post[i, j] = 255\n",
    "                    \n",
    "                    for (offset_i, offset_j) in structuring_elem_offsets:\n",
    "                        if inImage(i + offset_i, j + offset_j, rows, cols):\n",
    "                            acc[i + offset_i, j + offset_j] = 0\n",
    "                            src_post[i + offset_i, j + offset_j] = 0\n",
    "                    overlapped = overlapStructElem(src, acc_cpy, src_post, i, j, structuring_elem, False, False)\n",
    "                    ret_images.append(zoom_in(overlapped, 3)) # add to the list of frames    \n",
    "\n",
    "        overlapped = overlapStructElem(src, acc, src_post, last_i, last_j, structuring_elem, False, False)\n",
    "        ret_images.append(zoom_in(overlapped, 3))\n",
    "        src = np.copy(acc)\n",
    "\n",
    "    return ret_images\n",
    "\n",
    "def customErosionWithVisualization(src, structuring_elem, iterations):\n",
    "    \"\"\"\n",
    "    Performs an erosion on the source image. It builds a list of images representing\n",
    "    intermmediate steps through the algorithm\n",
    "    \"\"\"\n",
    "    rows, cols = src.shape\n",
    "    acc = np.copy(src)\n",
    "    structuring_elem_offsets = getOffsets(structuring_elem)\n",
    "    ret_images = []\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                curr_pixel = src[i, j]\n",
    "                if curr_pixel == 0:\n",
    "                    last_i, last_j = i, j\n",
    "\n",
    "                    acc_cpy = np.copy(acc)\n",
    "                    src_after = np.copy(src)\n",
    "\n",
    "                    all_neigbors_are_object = True\n",
    "                    for (offset_i, offset_j) in structuring_elem_offsets:\n",
    "                        if inImage(i + offset_i, j + offset_j, rows, cols):\n",
    "                            if src[i + offset_i, j + offset_j] == 255:\n",
    "                                all_neigbors_are_object = False\n",
    "                                break\n",
    "\n",
    "                    if all_neigbors_are_object:\n",
    "                        acc[i, j] = 0 # color the origin as object\n",
    "                        src_after[i, j] = 0\n",
    "                    else:\n",
    "                        acc[i, j] = 255\n",
    "                        src_after[i, j] = 255\n",
    "                    \n",
    "                    ovelapped = overlapStructElem(src, acc_cpy, src_after, i, j, structuring_elem, False, False)\n",
    "                    ret_images.append(zoom_in(ovelapped, 3))\n",
    "                    \n",
    "                    ovelapped = overlapStructElem(src, acc_cpy, src_after, i, j, structuring_elem, not all_neigbors_are_object, all_neigbors_are_object)\n",
    "                    ret_images.append(zoom_in(ovelapped, 3))\n",
    "        \n",
    "        ovelapped = overlapStructElem(src, acc, src_after, last_i, last_j, structuring_elem, False, False)\n",
    "        ret_images.append(zoom_in(ovelapped, 3))\n",
    "\n",
    "        src = np.copy(acc)\n",
    "\n",
    "    return ret_images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "767f200d",
   "metadata": {},
   "source": [
    "### Generating the desired gifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2adc39a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(isDilation, input_path, structuring_element, iterations, output_path, frame_duration) :\n",
    "    input_img = cv.imread(input_path, cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if isDilation:    \n",
    "        frames = customDilationWithVisualization(input_img, structuring_element, iterations)\n",
    "    else:   \n",
    "        frames = customErosionWithVisualization(input_img, structuring_element, iterations)\n",
    "    \n",
    "    createGifVariableSpeed(frames, output_path, frame_duration, True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9846ad0b",
   "metadata": {},
   "source": [
    "#### Dilation Gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7959d3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    struct_element = (np.array([[1,0,1]]), (0, 1))\n",
    "    main(True, \"./img/vertical_line.bmp\", struct_element, 2, \"./outDilation/dilation_vertical_gif.gif\", 300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e7b73cd",
   "metadata": {},
   "source": [
    "#### Erosion Gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f407c02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "magick convert -verbose -delay 35 ./outErosion\\frame_0.bmp -delay 35 ./outErosion\\frame_1.bmp -delay 35 ./outErosion\\frame_2.bmp -delay 35 ./outErosion\\frame_3.bmp -delay 35 ./outErosion\\frame_4.bmp -delay 35 ./outErosion\\frame_5.bmp -delay 35 ./outErosion\\frame_6.bmp -delay 35 ./outErosion\\frame_7.bmp -delay 35 ./outErosion\\frame_8.bmp -delay 35 ./outErosion\\frame_9.bmp -delay 35 ./outErosion\\frame_10.bmp -delay 35 ./outErosion\\frame_11.bmp -delay 35 ./outErosion\\frame_12.bmp -delay 35 ./outErosion\\frame_13.bmp -delay 35 ./outErosion\\frame_14.bmp -delay 35 ./outErosion\\frame_15.bmp -delay 35 ./outErosion\\frame_16.bmp -delay 35 ./outErosion\\frame_17.bmp -delay 35 ./outErosion\\frame_18.bmp -delay 35 ./outErosion\\frame_19.bmp -delay 35 ./outErosion\\frame_20.bmp -delay 35 ./outErosion\\frame_21.bmp -delay 35 ./outErosion\\frame_22.bmp -delay 35 ./outErosion\\frame_23.bmp -delay 35 ./outErosion\\frame_24.bmp -delay 35 ./outErosion\\frame_25.bmp -delay 35 ./outErosion\\frame_26.bmp -delay 35 ./outErosion\\frame_27.bmp -delay 35 ./outErosion\\frame_28.bmp -delay 35 ./outErosion\\frame_29.bmp -delay 35 ./outErosion\\frame_30.bmp -delay 35 ./outErosion\\frame_31.bmp -delay 35 ./outErosion\\frame_32.bmp -delay 35 ./outErosion\\frame_33.bmp -delay 35 ./outErosion\\frame_34.bmp -delay 35 ./outErosion\\frame_35.bmp -delay 35 ./outErosion\\frame_36.bmp -delay 35 ./outErosion\\frame_37.bmp -delay 35 ./outErosion\\frame_38.bmp -delay 35 ./outErosion\\frame_39.bmp -delay 35 ./outErosion\\frame_40.bmp -delay 35 ./outErosion\\frame_41.bmp -delay 17 ./outErosion\\frame_42.bmp -delay 17 ./outErosion\\frame_43.bmp -delay 17 ./outErosion\\frame_44.bmp -delay 17 ./outErosion\\frame_45.bmp -delay 17 ./outErosion\\frame_46.bmp -delay 17 ./outErosion\\frame_47.bmp -delay 17 ./outErosion\\frame_48.bmp -delay 17 ./outErosion\\frame_49.bmp -delay 17 ./outErosion\\frame_50.bmp -delay 17 ./outErosion\\frame_51.bmp -delay 17 ./outErosion\\frame_52.bmp -delay 17 ./outErosion\\frame_53.bmp -delay 17 ./outErosion\\frame_54.bmp -delay 17 ./outErosion\\frame_55.bmp -delay 17 ./outErosion\\frame_56.bmp -delay 17 ./outErosion\\frame_57.bmp -delay 17 ./outErosion\\frame_58.bmp -delay 17 ./outErosion\\frame_59.bmp -delay 17 ./outErosion\\frame_60.bmp -delay 17 ./outErosion\\frame_61.bmp -delay 17 ./outErosion\\frame_62.bmp -delay 17 ./outErosion\\frame_63.bmp -delay 17 ./outErosion\\frame_64.bmp -delay 17 ./outErosion\\frame_65.bmp -delay 17 ./outErosion\\frame_66.bmp -delay 17 ./outErosion\\frame_67.bmp -delay 17 ./outErosion\\frame_68.bmp -delay 17 ./outErosion\\frame_69.bmp -delay 17 ./outErosion\\frame_70.bmp -delay 17 ./outErosion\\frame_71.bmp -delay 17 ./outErosion\\frame_72.bmp -delay 17 ./outErosion\\frame_73.bmp -delay 17 ./outErosion\\frame_74.bmp -delay 17 ./outErosion\\frame_75.bmp -delay 17 ./outErosion\\frame_76.bmp -delay 17 ./outErosion\\frame_77.bmp -delay 17 ./outErosion\\frame_78.bmp -delay 17 ./outErosion\\frame_79.bmp -delay 17 ./outErosion\\frame_80.bmp -delay 17 ./outErosion\\frame_81.bmp -delay 17 ./outErosion\\frame_82.bmp -delay 17 ./outErosion\\frame_83.bmp -delay 17 ./outErosion\\frame_84.bmp -delay 11 ./outErosion\\frame_85.bmp -delay 11 ./outErosion\\frame_86.bmp -delay 11 ./outErosion\\frame_87.bmp -delay 11 ./outErosion\\frame_88.bmp -delay 11 ./outErosion\\frame_89.bmp -delay 11 ./outErosion\\frame_90.bmp -delay 11 ./outErosion\\frame_91.bmp -delay 11 ./outErosion\\frame_92.bmp -delay 11 ./outErosion\\frame_93.bmp -delay 11 ./outErosion\\frame_94.bmp -delay 11 ./outErosion\\frame_95.bmp -delay 11 ./outErosion\\frame_96.bmp -delay 11 ./outErosion\\frame_97.bmp -delay 11 ./outErosion\\frame_98.bmp -delay 11 ./outErosion\\frame_99.bmp -delay 11 ./outErosion\\frame_100.bmp -delay 11 ./outErosion\\frame_101.bmp -delay 11 ./outErosion\\frame_102.bmp -delay 11 ./outErosion\\frame_103.bmp -delay 11 ./outErosion\\frame_104.bmp -delay 11 ./outErosion\\frame_105.bmp -delay 11 ./outErosion\\frame_106.bmp -delay 11 ./outErosion\\frame_107.bmp -delay 11 ./outErosion\\frame_108.bmp -delay 11 ./outErosion\\frame_109.bmp -delay 11 ./outErosion\\frame_110.bmp -delay 11 ./outErosion\\frame_111.bmp -delay 11 ./outErosion\\frame_112.bmp -delay 11 ./outErosion\\frame_113.bmp -delay 11 ./outErosion\\frame_114.bmp -delay 11 ./outErosion\\frame_115.bmp -delay 11 ./outErosion\\frame_116.bmp -delay 11 ./outErosion\\frame_117.bmp -delay 11 ./outErosion\\frame_118.bmp -delay 11 ./outErosion\\frame_119.bmp -delay 11 ./outErosion\\frame_120.bmp -delay 11 ./outErosion\\frame_121.bmp -delay 11 ./outErosion\\frame_122.bmp -delay 11 ./outErosion\\frame_123.bmp -delay 11 ./outErosion\\frame_124.bmp -delay 11 ./outErosion\\frame_125.bmp -delay 11 ./outErosion\\frame_126.bmp -delay 11 ./outErosion\\frame_127.bmp -delay 11 ./outErosion\\frame_128.bmp -delay 11 ./outErosion\\frame_129.bmp -delay 11 ./outErosion\\frame_130.bmp -delay 11 ./outErosion\\frame_131.bmp -delay 11 ./outErosion\\frame_132.bmp -delay 11 ./outErosion\\frame_133.bmp -delay 11 ./outErosion\\frame_134.bmp -delay 11 ./outErosion\\frame_135.bmp -delay 11 ./outErosion\\frame_136.bmp -delay 11 ./outErosion\\frame_137.bmp -delay 11 ./outErosion\\frame_138.bmp -delay 11 ./outErosion\\frame_139.bmp -delay 11 ./outErosion\\frame_140.bmp -delay 11 ./outErosion\\frame_141.bmp -delay 11 ./outErosion\\frame_142.bmp -delay 11 ./outErosion\\frame_143.bmp -delay 11 ./outErosion\\frame_144.bmp -delay 11 ./outErosion\\frame_145.bmp -delay 11 ./outErosion\\frame_146.bmp -delay 11 ./outErosion\\frame_147.bmp -delay 11 ./outErosion\\frame_148.bmp -delay 11 ./outErosion\\frame_149.bmp -delay 11 ./outErosion\\frame_150.bmp -delay 11 ./outErosion\\frame_151.bmp -delay 11 ./outErosion\\frame_152.bmp -delay 11 ./outErosion\\frame_153.bmp -delay 11 ./outErosion\\frame_154.bmp -delay 11 ./outErosion\\frame_155.bmp -delay 11 ./outErosion\\frame_156.bmp -delay 11 ./outErosion\\frame_157.bmp -delay 11 ./outErosion\\frame_158.bmp -delay 11 ./outErosion\\frame_159.bmp -delay 11 ./outErosion\\frame_160.bmp -delay 11 ./outErosion\\frame_161.bmp -delay 11 ./outErosion\\frame_162.bmp -delay 11 ./outErosion\\frame_163.bmp -delay 11 ./outErosion\\frame_164.bmp -delay 11 ./outErosion\\frame_165.bmp -delay 11 ./outErosion\\frame_166.bmp -delay 11 ./outErosion\\frame_167.bmp -delay 11 ./outErosion\\frame_168.bmp -delay 11 ./outErosion\\frame_169.bmp -delay 140 ./outErosion\\frame_170.bmp -loop 0 ./outErosion\\output.gif \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    struct_element = (np.array([[1,1,1],[1,1,1],[1,1,1]]), (1, 1))\n",
    "    main(False, \"./img/infinity.bmp\", struct_element, 1, \"./outErosion\", 35 )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f93ffb6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cc31175",
   "metadata": {},
   "source": [
    "# Region Filling Visualization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c09063f",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dcf4ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complementImg(src):\n",
    "    rows, cols = src.shape\n",
    "    dst = np.copy(src)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if src[i, j] == 255:\n",
    "                dst[i, j] = 0\n",
    "            else:\n",
    "                dst[i, j] = 255\n",
    "\n",
    "    return dst\n",
    "\n",
    "def dilation(src, structuring_element):\n",
    "    \"\"\"\n",
    "    Performs a dilation on the source image. It builds a list of images representing\n",
    "    intermmediate steps through the algorithm\n",
    "    \"\"\"\n",
    "    rows, cols = src.shape\n",
    "    structuring_elem_offsets = getOffsets(structuring_element)\n",
    "\n",
    "    acc = np.copy(src) # accumulator\n",
    "        \n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if src[i, j] == 0:      \n",
    "                # mark the center as background\n",
    "                acc[i, j] = 255 \n",
    "                for (offset_i, offset_j) in structuring_elem_offsets:\n",
    "                    if inImage(i + offset_i, j + offset_j, rows, cols):\n",
    "                        acc[i + offset_i, j + offset_j] = 0\n",
    "    return acc\n",
    "\n",
    "def intersect(mat1, mat2):\n",
    "    \"\"\"\n",
    "    Assumes the images have the same size\n",
    "    \"\"\"\n",
    "    rows, cols = mat1.shape\n",
    "    dst = np.full((rows, cols), 255, np.uint8)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if (mat1[i, j] == mat2[i, j] and mat1[i, j] == 0):\n",
    "                dst[i, j] = 0\n",
    "\n",
    "    return dst\n",
    "\n",
    "def union(mat1, mat2):\n",
    "    rows, cols = mat1.shape\n",
    "    dst = np.full((rows, cols), 255, np.uint8)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if (mat1[i, j] == 0 or mat2[i, j] == 0):\n",
    "                dst[i, j] = 0\n",
    "    return dst\n",
    "\n",
    "def computeArea(src): \n",
    "    rows, cols = src.shape\n",
    "    area = 0\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if src[i, j] == 0:\n",
    "                area += 1 \n",
    "    return area\n",
    "\n",
    "def centerOfMass(src):\n",
    "    rows, cols = src.shape\n",
    "    row_sum = 0\n",
    "    col_sum = 0\n",
    "    area = computeArea(src)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if src[i, j] == 0:\n",
    "                row_sum += i\n",
    "                col_sum += j\n",
    "\n",
    "    center_i = int (row_sum / area)\n",
    "    center_j = int (col_sum / area)\n",
    "\n",
    "    return (center_i, center_j)\n",
    "\n",
    "def snapshotGenerator(left, dilated, right, option):\n",
    "    \"\"\"\n",
    "    Generate snapshot from the region filling algorithm\n",
    "    Option: 0 - just place images side by side\n",
    "            1 - in the left part show intersection while in the right part show the remaining part\n",
    "    \"\"\"\n",
    "    rows, cols = left.shape\n",
    "    to_return = np.full((rows, 2 * cols, 3), 255, np.uint8)\n",
    "    if option == 0:\n",
    "        to_return[:, 0:cols, 0] = left\n",
    "        to_return[:, 0:cols, 1] = left\n",
    "        to_return[:, 0:cols, 2] = left\n",
    "\n",
    "        to_return[:, cols:(2 * cols), 0] = right\n",
    "        to_return[:, cols:(2 * cols), 1] = right\n",
    "        to_return[:, cols:(2 * cols), 2] = right\n",
    "        \n",
    "    elif option == 1:\n",
    "        # left part\n",
    "        to_return[:, 0:cols, 0] = left\n",
    "        to_return[:, 0:cols, 1] = left\n",
    "        to_return[:, 0:cols, 2] = left\n",
    "\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                if left[i, j] == dilated[i, j] and dilated[i, j] == 0: # draw intersection dark green\n",
    "                    to_return[i, j, 1] = 99\n",
    "                    to_return[i, j, 2] = 18\n",
    "                else: # draw the rest of pixels in red\n",
    "                    if dilated[i, j] == 0:   \n",
    "                        to_return[i, j, 0] = 0\n",
    "                        to_return[i, j, 1] = 0\n",
    "                        to_return[i, j, 2] = 255\n",
    "\n",
    "        # right part\n",
    "        to_return[:, cols:(2 * cols), 0] = right\n",
    "        to_return[:, cols:(2 * cols), 1] = right\n",
    "        to_return[:, cols:(2 * cols), 2] = right\n",
    "    \n",
    "    return to_return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b69b5eef",
   "metadata": {},
   "source": [
    "### Region Filling Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb4bd923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regionFillingWithVisualization(src, struct_element):\n",
    "    rows, cols = src.shape\n",
    "    dst = np.full((rows, cols), 255, np.uint8)\n",
    "\n",
    "    # Color the center of mass black\n",
    "    (x_start, y_start) = centerOfMass(src)\n",
    "    dst[x_start, y_start] = 0\n",
    "\n",
    "    complement = complementImg(src)\n",
    "    snapshots = [] # store the output frames\n",
    "    \n",
    "    sn0 = snapshotGenerator(src, dst, complement, 0) # initial state (original | complemented)\n",
    "    snapshots.append(zoom_in(sn0, 3))\n",
    "    snapshots.append(zoom_in(sn0, 3))\n",
    "    snapshots.append(zoom_in(sn0, 3))\n",
    "\n",
    "    while (True):\n",
    "        prv = np.copy(dst)\n",
    "        sn1 = snapshotGenerator(complement, dst, dst, 0) # (complement | current dst)\n",
    "        snapshots.append(zoom_in(sn1, 3))\n",
    "        \n",
    "        dst = dilation(dst, struct_element)\n",
    "        dilated_cpy = np.copy(dst)\n",
    "        sn2 = snapshotGenerator(complement, dst, dst, 0) # (complement | dst dilated)\n",
    "        snapshots.append(zoom_in(sn2, 3))\n",
    "        \n",
    "        dst = intersect(dst, complement)\n",
    "        \n",
    "        sn3_0 = snapshotGenerator(complement, dilated_cpy, dilated_cpy, 1) # (complement overlapped with dst dilated | dst dilated)\n",
    "        snapshots.append(zoom_in(sn3_0, 3))\n",
    "\n",
    "        sn3_1 = snapshotGenerator(complement, dilated_cpy, dst, 1) # (complement overlapped with dst dilated | intersection of the two)\n",
    "        snapshots.append(zoom_in(sn3_1, 3))\n",
    "        \n",
    "        if np.array_equal(dst, prv):\n",
    "            break\n",
    "\n",
    "    final_result = union(dst, src)\n",
    "    sn4 = snapshotGenerator(complement, final_result, final_result, 0) # (complement | final result)\n",
    "    snapshots.append(zoom_in(sn4, 3))\n",
    "\n",
    "    sn5 = snapshotGenerator(src, final_result, final_result, 0) # (source | final result)\n",
    "    snapshots.append(zoom_in(sn5, 3))\n",
    "\n",
    "    return snapshots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccbbd961",
   "metadata": {},
   "source": [
    "### Generate Visualization Gif"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f72adbef",
   "metadata": {},
   "source": [
    "#### Gif explanation:\n",
    "- **first** iteration: left = original, right = complemented\n",
    "- **intermmediary** iterations of the algorithm contains 3 frames:\n",
    "\n",
    "|Step|Left Image Meaning|Right Image Meaning|\n",
    "|-|-|-|\n",
    "|1|complemented original|current aux image (built starting from a point, through dilation with struct. element)|\n",
    "|2|complemented original|dilated aux image|\n",
    "|3|complemented original intersected with the dilated aux image (pixels outside intersection are red)|dilated aux image|\n",
    "|4|complemented original intersected with the dilated aux image|aux image after the pixels outside the intersection with complemented original (red) were deleted|\n",
    "\n",
    "- **last** iteration: left = original, right = final image obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90031468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    input_img = cv.imread(\"./img/l.bmp\", cv.IMREAD_GRAYSCALE)\n",
    "    struct_elem = (np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]]), (1, 1))\n",
    "    frames = regionFillingWithVisualization(input_img, struct_elem)\n",
    "    # Generate region filling gif\n",
    "    createGifVariableSpeed(frames, \".\\\\outRegionFilling\", 40, True) # approx 25 sec\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
